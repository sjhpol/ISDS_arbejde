{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Exam project of group 26\n",
                "### Group members:\n",
                "- Baltazar Dydensborg\n",
                "- Johan Kielgast Ladelund\n",
                "- Laura Weile\n",
                "- Simon Juul Hansen\n",
                "\n",
                "### Research Question:\n",
                "???"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### All of the dependency imports"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import pandas as pd\n",
                "import requests\n",
                "from bs4 import BeautifulSoup\n",
                "import datetime\n",
                "from tqdm import tqdm\n",
                "import warnings\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Scraping betting data from Oddsportal.com"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Example of URLs\n",
                "newest_season_url = 'https://www.oddsportal.com/soccer/denmark/superliga/results/'\n",
                "previous_season_url = lambda year_span: f'https://www.oddsportal.com/soccer/denmark/superliga-{year_span}/results/'\n",
                "previous_season_url('2020-2021')\n",
                "prev_url_example = 'https://www.oddsportal.com/soccer/denmark/superliga-2020-2021/results/'"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# requesting html data\n",
                "page = requests.get('https://www.oddsportal.com/soccer/denmark/superliga-2020-2021/results/#/page/2/')\n",
                "soup = BeautifulSoup(page.content, 'html.parser')\n",
                "soup.find('body')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## FIRST PROBLEM WITH ODDSPORTAL.COM:\n",
                "### The HTML data is being retrieved via a JavaScript Query, so we can't directly get it via scraping the website with 'requests'.\n",
                "### We need to find a solution to getting the HTML data via the JS query, possible via Selenium"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# www.football-data.co.uk"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df = pd.read_csv('https://www.football-data.co.uk/mmz4281/2021/E0.csv')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "url_template = lambda year_span: f'https://www.football-data.co.uk/mmz4281/{year_span}/E0.csv'\n",
                "dict_df = {}\n",
                "\n",
                "first_years = [f'{x:02}' for x in range(0,21)]\n",
                "second_years = [f'{x:02}' for x in range(1,22)]\n",
                "final_years = [x+y for x,y in zip(first_years,second_years)]\n",
                "final_years\n",
                "\n",
                "for year in final_years:\n",
                "    df_temp = pd.read_csv(url_template(year), nrows = 1)\n",
                "    df_temp2 = pd.read_csv(url_template(year), usecols = df_temp.columns)\n",
                "    dict_df[year] = df_temp2"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df_temp = pd.read_csv(f'https://www.football-data.co.uk/mmz4281/{final_years[3]}/E0.csv',nrows=1)\n",
                "df_temp.columns \n",
                "df_0203 = pd.read_csv(f'https://www.football-data.co.uk/mmz4281/{final_years[3]}/E0.csv', usecols = df_temp.columns)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "res = requests.get('https://fb.oddsportal.com/ajax-sport-country-tournament-archive/1/4l3rT0aP/X0/1/0/1/')\n",
                "res.content"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Elpriser fra Nordpool"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "url = 'https://www.nordpoolgroup.com/historical-market-data/'\n",
                "el_res = requests.get(url)\n",
                "soup = BeautifulSoup(el_res.content, 'html.parser')\n",
                "soup.find('a')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "df = pd.read_csv('https://www.nordpoolgroup.com/4a2916/globalassets/marketdata-excel-files/elspot-prices_2021_hourly_dkk.xls', sep='\\t', skiprows=10)\n",
                "df"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "dls = \"https://www.nordpoolgroup.com/4a2916/globalassets/marketdata-excel-files/elspot-prices_2021_hourly_dkk.xls\"\n",
                "resp = requests.get(dls)\n",
                "\n",
                "with open('2021.xlsx', 'wb') as output:\n",
                "    output.write(resp.content)\n",
                "    output.close()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Vejr data fra DMI API"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Constants\n",
                "\n",
                "metObsAPIKey = 'c4503ba1-28d4-45c5-850a-974e98bbb3e0'\n",
                "climateDataAPIKEy = 'ac27b332-bde2-4138-a53e-f0ca82cf3667'\n",
                "stationId = 6183\n",
                "\n",
                "dmi_url= lambda API_KEY: f'https://dmigw.govcloud.dk/v2/metObs/collections/observation/items?limit=300000&stationId=06184&parameterId=temp_dry&bbox=7,54,16,58&datetime=2015-01-01T00:00:00Z/2021-08-01T00:00:00Z&api-key={API_KEY}'\n",
                "dmi_url_id= lambda API_KEY, id: f'https://dmigw.govcloud.dk/v2/metObs/collections/observation/items?limit=300000&stationId=06184&parameterId={id}&bbox=7,54,16,58&datetime=2015-01-01T00:00:00Z/2021-08-01T00:00:00Z&api-key={API_KEY}'\n",
                "dmi_url_allID= lambda API_KEY: f'https://dmigw.govcloud.dk/v2/metObs/collections/observation/items?limit=300000&stationId=06184&bbox=7,54,16,58&datetime=2015-01-01T00:00:00Z/2021-08-01T00:00:00Z&api-key={API_KEY}'\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "source": [
                "def metObsData(stat, start_date, end_date, stationId = '06183', apiKey = metObsAPIKey):\n",
                "    \"\"\"\n",
                "    Function that takes a parameter ID and searches for all observations from DMI\n",
                "    for the given dates, where the date format is given as 'YYYY-MM-DD'\n",
                "    \"\"\"\n",
                "\n",
                "    # Define constants to be used in the function\n",
                "    url= lambda API_KEY, id, startDate, endDate, stationId: f'https://dmigw.govcloud.dk/v2/metObs/collections/observation/items?limit=300000&stationId={stationId}&parameterId={id}&bbox=7,54,16,58&datetime={startDate}T00:00:00Z/{endDate}T00:00:00Z&api-key={API_KEY}'\n",
                "    local_counter = 1\n",
                "    ErrorCounter = 0\n",
                "    stationCounter = 0\n",
                "    stationList = ['06184', '06186', '06187', '06188']\n",
                "\n",
                "    while True:\n",
                "        try:\n",
                "            temp_url = url(apiKey, stat, start_date, end_date, stationId)\n",
                "            ErrorCounter += 1\n",
                "\n",
                "            json_dmi = requests.get(temp_url).json()\n",
                "            prop = [item['properties'] for item in json_dmi['features']]\n",
                "            temp_df = pd.DataFrame(prop)\n",
                "            \n",
                "            temp_df['observed'].drop_duplicates(inplace = True)\n",
                "            temp_df.index = pd.to_datetime(temp_df['observed'])\n",
                "            temp_df = temp_df.tz_convert('CET')\n",
                "\n",
                "            if temp_df.index[-1].date() != datetime.date.fromisoformat(start_date):\n",
                "                            \n",
                "                if local_counter == 1:\n",
                "                    df = temp_df.copy()\n",
                "                    local_counter += 1\n",
                "                elif local_counter > 1:\n",
                "                    df = pd.concat([df,temp_df])\n",
                "                else:\n",
                "                    warnings.warn(\"Something went wrong with the local counter in IF\")\n",
                "\n",
                "                end_date = temp_df.index[-1].date().strftime(\"%Y-%m-%d\")\n",
                "                continue\n",
                "            else:\n",
                "                if local_counter == 1:\n",
                "                    df = temp_df\n",
                "                elif local_counter > 1:\n",
                "                    df = pd.concat([df,temp_df])\n",
                "                else:\n",
                "                    warnings.warn(\"Something went wrong with the local counter in ELSE\")\n",
                "\n",
                "                break\n",
                "            \n",
                "\n",
                "\n",
                "        except KeyError as e:\n",
                "\n",
                "            try:\n",
                "                stationId = stationList[stationCounter]\n",
                "                stationCounter += 1\n",
                "                continue\n",
                "            except IndexError as i:\n",
                "                if ErrorCounter == 1:\n",
                "                    warnings.warn(f\"The requested stat {stat} isn't available for any default stations\")\n",
                "                else:\n",
                "                    warnings.warn(f\"The requested stat {stat} isn't available for any default stations for the daterange: {start_date} - {end_date}\")\n",
                "                return None\n",
                "        \n",
                "    return df\n",
                "\n",
                "        \n",
                "    "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "source": [
                "def climateData(stat, start_date, end_date, stationId = '06184',apiKey = climateDataAPIKEy):\n",
                "    \"\"\"\n",
                "    Function that takes a parameter ID and searches for all observations from DMI\n",
                "    for the given dates, where the date format is given as 'YYYY-MM-DD'\n",
                "    \"\"\"\n",
                "\n",
                "    # Define constants to be used in the function\n",
                "    url= lambda API_KEY, id, startDate, endDate, stationId: f'https://dmigw.govcloud.dk/v2/climateData/collections/stationValue/items?timeResolution=hour&limit=300000&stationId={stationId}&parameterId={id}&datetime={startDate}T00:00:00Z/{endDate}T00:00:00Z&api-key={API_KEY}'\n",
                "    local_counter = 1\n",
                "    ErrorCounter = 0\n",
                "    stationCounter = 0\n",
                "    stationList = ['06181', '06186', '06187', '06188']\n",
                "\n",
                "    while True:\n",
                "        try:\n",
                "            temp_url = url(apiKey, stat, start_date, end_date, stationId)\n",
                "            ErrorCounter += 1\n",
                "\n",
                "            json_dmi = requests.get(temp_url).json()\n",
                "            prop = [item['properties'] for item in json_dmi['features']]\n",
                "            temp_df = pd.DataFrame(prop)\n",
                "            \n",
                "            temp_df['to'].drop_duplicates(inplace = True)\n",
                "            temp_df.index = pd.to_datetime(temp_df['to'])\n",
                "            #temp_df = temp_df.tz_convert('CET')\n",
                "\n",
                "            if temp_df.index[-1].date() != datetime.date.fromisoformat(start_date):\n",
                "                            \n",
                "                if local_counter == 1:\n",
                "                    df = temp_df.copy()\n",
                "                    local_counter += 1\n",
                "                elif local_counter > 1:\n",
                "                    df = pd.concat([df,temp_df])\n",
                "                else:\n",
                "                    warnings.warn(\"Something went wrong with the local counter in IF\")\n",
                "\n",
                "                end_date = temp_df.index[-1].date().strftime(\"%Y-%m-%d\")\n",
                "                warnings.warn('Loop loop date wrong')\n",
                "                continue\n",
                "            else:\n",
                "                if local_counter == 1:\n",
                "                    df = temp_df\n",
                "                elif local_counter > 1:\n",
                "                    df = pd.concat([df,temp_df])\n",
                "                else:\n",
                "                    warnings.warn(\"Something went wrong with the local counter in ELSE\")\n",
                "\n",
                "                break\n",
                "            \n",
                "\n",
                "\n",
                "        except KeyError as e:\n",
                "\n",
                "            try:\n",
                "                stationId = stationList[stationCounter]\n",
                "                stationCounter += 1\n",
                "                warnings.warn('Loop loop station wrong')\n",
                "                continue\n",
                "            except IndexError as i:\n",
                "                if ErrorCounter == 1:\n",
                "                    warnings.warn(f\"The requested stat {stat} isn't available for any default stations\")\n",
                "                else:\n",
                "                    warnings.warn(f\"The requested stat {stat} isn't available for any default stations for the daterange: {start_date} - {end_date}\")\n",
                "                return None\n",
                "        \n",
                "    return df\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 157,
            "source": [
                "def TransformMetObsData(df):\n",
                "    df = df\n",
                "    df['hour'] = df.index.hour\n",
                "    df['date'] = df.index.date\n",
                "    df = df.drop_duplicates(['parameterId', 'date','hour'])\\\n",
                "            .drop(['created', 'stationId'], axis = 1)\\\n",
                "            .sort_values(by = ['date', 'hour'], ascending = [False, False])\\\n",
                "            .copy()\n",
                "    \n",
                "    df_new = df.groupby(['parameterId', 'date', 'hour'])['value'].mean()\\\n",
                "            .unstack(level = 0)\\\n",
                "            .reset_index().rename(columns={df.index.name:None})\n",
                "\n",
                "    return df_new\n",
                "    "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 158,
            "source": [
                "def transformClimateData(df):\n",
                "    df = df\n",
                "    df = df.tz_convert('CET')\n",
                "    df['hour'] = df.index.hour\n",
                "    df['date'] = df.index.date\n",
                "    df = df.drop_duplicates(['parameterId', 'date','hour'])\\\n",
                "            .drop(['calculatedAt', 'created', 'from', 'qcStatus', 'timeResolution', 'validity'], axis = 1)\\\n",
                "            .sort_values(by = ['date', 'hour'], ascending = [False, False])\\\n",
                "            .copy()\n",
                "    \n",
                "    df_new = df.groupby(['parameterId', 'date', 'hour'])['value'].mean()\\\n",
                "            .unstack(level = 0)\\\n",
                "            .reset_index().rename(columns={df.index.name:None})\n",
                "\n",
                "    return df_new"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "source": [
                "list_of_stats=['wind_min', 'wind_max', 'visibility', 'cloud_cover', 'cloud_height', 'temp_dry', 'wind_speed', 'wind_dir', 'pressure', 'humidity']\n",
                "\n",
                "dict_df = dict()\n",
                "for stat in tqdm(list_of_stats):\n",
                "    dict_df[stat] = metObsData(stat, '2015-01-01', '2021-08-01')\n",
                "\n",
                "new_df_met = pd.concat(dict_df.values())\n",
                "transform_df_met = TransformMetObsData(new_df_met)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/10 [00:00<?, ?it/s]<ipython-input-101-bfbaca18790e>:65: UserWarning: The requested stat wind_min isn't available for any default stations for the daterange: 2015-01-01 - 2015-01-02\n",
                        "  warnings.warn(f\"The requested stat {stat} isn't available for any default stations for the daterange: {start_date} - {end_date}\")\n",
                        "100%|██████████| 10/10 [06:39<00:00, 39.91s/it]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "source": [
                "list_of_stats_climate =['bright_sunshine', 'mean_radiation', 'mean_pressure', 'mean_wind_dir', 'acc_precip', 'temp_grass', 'mean_relative_hum', 'mean_temp']\n",
                "\n",
                "dict_df_climate = dict()\n",
                "for stat in tqdm(list_of_stats_climate):\n",
                "    dict_df_climate[stat] = climateData(stat, '2015-01-01', '2021-08-01')\n",
                "\n",
                "new_df_climate = pd.concat(dict_df_climate.values())\n",
                "transform_df_climate = transformClimateData(new_df_climate)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/8 [00:00<?, ?it/s]<ipython-input-103-e4323209ab18>:57: UserWarning: Loop loop station wrong\n",
                        "  warnings.warn('Loop loop station wrong')\n",
                        " 25%|██▌       | 2/8 [00:18<00:54,  9.01s/it]<ipython-input-103-e4323209ab18>:38: UserWarning: Loop loop date wrong\n",
                        "  warnings.warn('Loop loop date wrong')\n",
                        "100%|██████████| 8/8 [01:18<00:00,  9.78s/it]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 190,
            "source": [
                "def metObsPipeline(stats, start_date, end_date):\n",
                "    dict_df = dict()\n",
                "    for stat in tqdm(stats):\n",
                "        dict_df[stat] = metObsData(stat, start_date, end_date)\n",
                "\n",
                "    new_df_met = pd.concat(dict_df.values())\n",
                "    transform_df_met = TransformMetObsData(new_df_met)\n",
                "    return transform_df_met"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 189,
            "source": [
                "def climatePipeline(stats, start_date, end_date):\n",
                "    dict_df = dict()\n",
                "    for stat in tqdm(stats):\n",
                "        dict_df[stat] = climateData(stat, start_date, end_date)\n",
                "\n",
                "    new_df_climate = pd.concat(dict_df.values())\n",
                "    transform_df_climate = transformClimateData(new_df_climate)\n",
                "    return transform_df_climate"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 192,
            "source": [
                "def merger(df_met, df_climate):\n",
                "    merge_df = df_met.merge(df_climate, on = ['date', 'hour'], how = 'outer')\n",
                "    merge_df = merge_df.sort_values(by = ['date', 'hour'], ascending = [False, False]).reset_index(drop = True)\n",
                "    return merge_df"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 193,
            "source": [
                "def total_pipeline(met_stats, climate_stats, start_date, end_date):\n",
                "    df_met = metObsPipeline(met_stats, start_date, end_date)\n",
                "    df_climate = climatePipeline(climate_stats, start_date, end_date)\n",
                "    df_total = merger(df_met, df_climate)\n",
                "    return df_total"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.2",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.2 64-bit"
        },
        "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}